{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Wd3y53FOZjEe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HkbVanePYgwy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoConfig\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeTHES8qZjcw",
        "outputId": "cad864b0-f5f7-4257-f670-31281325893d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 2289,  1110,  1103,  1436,  4799,  1107,  1103,  1362,   119, 12418,\n",
              "          5303,  1233,  1110,  1103,  1211,  1927,  1569,  1264,  6142,  5230,\n",
              "          6331,  1110,  1103,  1211,  2265,  1233,  1526,   119]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer('Football is the best sport in the world. brazil is the most popular national team whereas Real Madrid is the most successfull club.',return_tensors='pt',add_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChudDqjDbAeR",
        "outputId": "e5a05ceb-888f-42b4-ea30-f94af5fe222f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-uncased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.30.1\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config=AutoConfig.from_pretrained('bert-base-uncased')\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8nm42uqybPtH"
      },
      "outputs": [],
      "source": [
        "embedding=nn.Embedding(config.vocab_size,config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yaSvh0YQcVJw"
      },
      "outputs": [],
      "source": [
        "text='Football is the best sport in the world. brazil is the most popular national team whereas Real Madrid is the most successfull club .'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-pBsQZVblCJ",
        "outputId": "6f0893ee-58f3-4782-b018-b6dbbd24f3f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 768])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qkv=embedding(tokenizer(text,return_tensors='pt',add_special_tokens=False)['input_ids'])\n",
        "qkv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4xXPmgdCiHv5"
      },
      "outputs": [],
      "source": [
        "def compute_dot_product(query,key,value):\n",
        "  batch_size=query.shape[0]\n",
        "  scale=torch.sqrt(torch.tensor(key.shape[-1])) # sqrt(64)\n",
        "  dot_prod=torch.matmul(query,key.transpose(-2,-1))/scale\n",
        "  weights=torch.softmax(dot_prod,dim=-1) # 1 x 28 x 12 x 12\n",
        "  return torch.matmul(weights,value) # M(1 x 28 x 12 x 12) * M(1 x 28 x 12 x 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_eVSmHsebqMv"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self,embedd_dim,num_heads):\n",
        "    super().__init__()\n",
        "    self.num_heads=num_heads # 12\n",
        "    self.head_dim=embedd_dim//num_heads # 768//12\n",
        "    self.wq=nn.Linear(self.head_dim,self.head_dim) \n",
        "    self.wk=nn.Linear(self.head_dim,self.head_dim)\n",
        "    self.wv=nn.Linear(self.head_dim,self.head_dim)\n",
        "  \n",
        "  def forward(self,query,key,value):\n",
        "    batch_size = query.size(0)\n",
        "    query=query.view(batch_size,-1,self.num_heads,self.head_dim) # 1 x 28 x 12 x 64\n",
        "    key=key.view(batch_size,-1,self.num_heads,self.head_dim) # 1 x 28 x 12 x 64\n",
        "    value=value.view(batch_size,-1,self.num_heads,self.head_dim) # 1 x 28 x 12 x 64\n",
        "    Q = self.wq(query) # 1 x 28 x 12 x 64\n",
        "    K = self.wk(key) # 1 x 28 x 12 x 64\n",
        "    V = self.wv(value) # 1 x 28 x 12 x 64\n",
        "    return compute_dot_product(Q,K,V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P39HqJpVoGIX"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,embdd_dim,num_heads):\n",
        "    super().__init__()    \n",
        "    self.embdd_dim=embdd_dim\n",
        "    self.att=SelfAttention(embdd_dim,num_heads)\n",
        "    self.fc=nn.Linear(embdd_dim,embdd_dim)\n",
        "\n",
        "  def forward(self,query,key,value):\n",
        "    attention=self.att(query,key,value) # 1 x 28 x 12 x 64\n",
        "    attention=attention.view(query.size(0),-1,self.embdd_dim) # 1 x 28 x 768\n",
        "    fc_out=self.fc(attention)\n",
        "    return attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpzORG0SyzfA",
        "outputId": "67acf6a9-98ed-469a-cd9c-fe880edb566c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 768])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MultiHeadAttention(768,12)(qkv,qkv,qkv).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "52L89RGZcnpq"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,embedd_dim):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(embedd_dim,embedd_dim*2)\n",
        "    self.fc2=nn.Linear(embedd_dim*2,embedd_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=F.gelu(self.fc1(x))\n",
        "    x=self.fc2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "COFbynZJcp--"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self,fn):\n",
        "    super().__init__()\n",
        "    self.fn=fn\n",
        "  \n",
        "  def forward(self,x):\n",
        "    res=x\n",
        "    x=self.fn(x)\n",
        "    x+=res\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HGGPatR1csgF"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "  def __init__(self,emb_size,num_heads,drop_p=0.3):\n",
        "    super().__init__()\n",
        "    self.attention=MultiHeadAttention(emb_size,num_heads)\n",
        "    self.norm1 = nn.LayerNorm(emb_size)\n",
        "    self.feed_forward = FeedForward(emb_size)\n",
        "    self.norm2 = nn.LayerNorm(emb_size)\n",
        "    self.dropout = nn.Dropout(drop_p)\n",
        "\n",
        "  def forward(self, x):\n",
        "    attention_out = self.attention(x, x, x)\n",
        "    x = x + self.dropout(attention_out)\n",
        "    x = self.norm1(x)\n",
        "    feed_forward_out = self.feed_forward(x)\n",
        "    x = x + self.dropout(feed_forward_out)\n",
        "    x = self.norm2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sJ5RpzMUA8W2"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Sequential):\n",
        "  def __init__(self, depth,emb_size, num_heads):\n",
        "      super().__init__(*[TransformerEncoderBlock(emb_size, num_heads) for _ in range(depth)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "x_AmnpUIDcnq"
      },
      "outputs": [],
      "source": [
        "Encoder=TransformerEncoder(depth=6,emb_size=config.hidden_size, num_heads=config.num_attention_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye_cWm_CDf_0",
        "outputId": "6cf0b356-68b9-4af7-bff3-2255fe9c228d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.5765, -0.8608,  1.8814,  ..., -0.2364,  0.9849, -1.3242],\n",
              "         [ 1.0313, -1.4313, -0.6305,  ..., -0.8745,  0.3363,  0.1722],\n",
              "         [ 0.2411,  0.0702, -1.1496,  ...,  0.0463,  0.3928, -0.9792],\n",
              "         ...,\n",
              "         [-0.6069,  0.8564,  0.7278,  ..., -0.9421,  0.5129,  0.2135],\n",
              "         [-0.0391,  0.3868,  0.4819,  ..., -0.0526,  0.7824, -0.4456],\n",
              "         [ 0.4336, -0.5663, -0.2589,  ..., -1.6420, -0.2041, -1.3425]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Encoder(qkv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1IdwNya1MP4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
